{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b829102",
   "metadata": {},
   "source": [
    "# Telecom X — Parte 2: Predicción de Cancelación (Churn)\n",
    "\n",
    "**Fecha:** 2025-08-10\n",
    "\n",
    "Este notebook está pensado para ejecutarse en **Google Colab**. Contiene el pipeline completo para:\n",
    "\n",
    "- Preparación y preprocesamiento de datos para modelado.\n",
    "- Entrenamiento y evaluación de varios modelos de clasificación (Regresión Logística, KNN, RandomForest, SVM).\n",
    "- Interpretación de resultados (coeficientes, importancia de variables) y recomendaciones estratégicas.\n",
    "\n",
    "Dataset (raw): https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar en Google Colab (descomenta si necesitas instalar paquetes)\n",
    "# !pip install --upgrade scikit-learn matplotlib pandas requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import requests, json\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "print('Librerías cargadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "url = \"https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json\"\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()\n",
    "df = pd.json_normalize(data)\n",
    "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "print('Registros:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columna churn\n",
    "possible_churn = [c for c in df.columns if 'churn' in c or 'cancel' in c or 'exit' in c or 'churned' in c]\n",
    "print('Columnas candidatas churn:', possible_churn)\n",
    "churn_col = possible_churn[0] if possible_churn else None\n",
    "print('Usando churn_col =', churn_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fabe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación básica\n",
    "df_model = df.copy()\n",
    "\n",
    "# Limpiar strings\n",
    "for c in df_model.select_dtypes(include='object').columns:\n",
    "    df_model[c] = df_model[c].str.strip()\n",
    "\n",
    "# Convertir a num donde tenga sentido\n",
    "for c in df_model.columns:\n",
    "    if df_model[c].dtype == object:\n",
    "        try:\n",
    "            df_model[c] = df_model[c].str.replace(',','').astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Mapear churn a 0/1 si existe\n",
    "if churn_col:\n",
    "    df_model[churn_col] = df_model[churn_col].astype(str).str.lower().map({'yes':1,'no':0,'y':1,'n':0,'true':1,'false':0}).astype(float)\n",
    "    df_model = df_model[df_model[churn_col].notna()]\n",
    "    df_model[churn_col] = df_model[churn_col].astype(int)\n",
    "\n",
    "print('Registros para modelado:', len(df_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06146971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de features (excluir identificadores)\n",
    "exclude = [churn_col, 'id', 'customerid', 'customer_id']\n",
    "features = [c for c in df_model.columns if c not in exclude]\n",
    "# eliminar columnas con único valor\n",
    "features = [c for c in features if df_model[c].nunique()>1]\n",
    "print('Features seleccionadas:', len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de features\n",
    "num_cols = df_model[features].select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in features if c not in num_cols]\n",
    "print('Numéricas:', num_cols[:10])\n",
    "print('Categóricas:', cat_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaeb0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División train/test\n",
    "X = df_model[features]\n",
    "y = df_model[churn_col]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2826f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, num_cols),\n",
    "                                               ('cat', categorical_transformer, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "models = {\n",
    "    'LogisticRegression': Pipeline([('pre', preprocessor), ('clf', LogisticRegression(max_iter=1000, solver='liblinear'))]),\n",
    "    'KNN': Pipeline([('pre', preprocessor), ('clf', KNeighborsClassifier())]),\n",
    "    'RandomForest': Pipeline([('pre', preprocessor), ('clf', RandomForestClassifier(n_estimators=200, random_state=42))]),\n",
    "    'SVM': Pipeline([('pre', preprocessor), ('clf', SVC(probability=True, kernel='rbf'))])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe.named_steps['clf'], 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    results[name] = {'pipe': pipe, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'auc': auc}\n",
    "    print('==', name, '==')\n",
    "    print('Accuracy:', acc, 'Precision:', prec, 'Recall:', rec, 'F1:', f1, 'AUC:', auc)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen\n",
    "res_df = pd.DataFrame([{**{'model':k}, **{m: results[k][m] for m in ['accuracy','precision','recall','f1','auc']}} for k in results]).set_index('model')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretabilidad: obtener nombres de features transformadas\n",
    "pre = preprocessor.fit(X_train)\n",
    "X_train_t = pre.transform(X_train)\n",
    "num_features = num_cols\n",
    "cat_features = list(pre.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_cols)) if len(cat_cols)>0 else []\n",
    "feature_names = num_features + cat_features\n",
    "print('Features transformadas:', len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression: coeficientes\n",
    "if 'LogisticRegression' in results:\n",
    "    lr = results['LogisticRegression']['pipe'].named_steps['clf']\n",
    "    coefs = lr.coef_[0]\n",
    "    coef_df = pd.DataFrame({'feature': feature_names, 'coef': coefs})\n",
    "    coef_df['abs'] = coef_df['coef'].abs()\n",
    "    coef_df = coef_df.sort_values('abs', ascending=False).head(20)\n",
    "    display(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53760fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest: importancias\n",
    "if 'RandomForest' in results:\n",
    "    rf = results['RandomForest']['pipe'].named_steps['clf']\n",
    "    importances = rf.feature_importances_\n",
    "    imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(20)\n",
    "    display(imp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0259bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for name, info in results.items():\n",
    "    pipe = info['pipe']\n",
    "    if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
    "        y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f8a27",
   "metadata": {},
   "source": [
    "## Conclusiones y recomendaciones\n",
    "\n",
    "- Resume los modelos comparados y su rendimiento (F1 y AUC).\n",
    "- Menciona las variables con mayor impacto según regresión logística y Random Forest.\n",
    "- Recomendaciones tácticas para retención basadas en las variables importantes.\n",
    "\n",
    "---\n",
    "\n",
    "**Siguientes pasos sugeridos:** grid-search de hiperparámetros, validación cruzada, probar XGBoost/LightGBM y despliegue del scoring en producción."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
